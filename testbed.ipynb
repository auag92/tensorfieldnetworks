{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apaar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from math import pi, sqrt\n",
    "import tensorfieldnetworks.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorfieldnetworks.utils as utils\n",
    "from tensorfieldnetworks.utils import FLOAT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_type_to_one_hot(atom_numbers, atom_order):\n",
    "    one_hot_dict = {atom_type: [1 if i == j else 0 for i in range(len(atom_order))]\n",
    "                    for j, atom_type in enumerate(atom_order)}\n",
    "    return list(map(lambda x: one_hot_dict[x], atom_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = 1000\n",
    "with connect('qm9.db') as conn:\n",
    "    qm9_coords = []\n",
    "    qm9_atoms = []\n",
    "    qm9_test_coords = []\n",
    "    qm9_test_atoms = []\n",
    "    for atoms in conn.select('4<natoms<=18', limit=training_set_size):\n",
    "        qm9_coords.append(atoms.positions)\n",
    "        qm9_atoms.append(atoms.numbers)\n",
    "    for atoms in conn.select('natoms=19', limit=training_set_size):\n",
    "        qm9_test_coords.append(atoms.positions)\n",
    "        qm9_test_atoms.append(atoms.numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_order = list(set(np.concatenate(qm9_atoms)))\n",
    "num_atom_types = len(atom_order)\n",
    "\n",
    "qm9_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_atoms))\n",
    "qm9_test_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_test_atoms))\n",
    "\n",
    "# BUILD NETWORK\n",
    "print(\"Building graph.\")\n",
    "\n",
    "# radial basis functions\n",
    "rbf_low = 0.\n",
    "rbf_high = 2.5\n",
    "rbf_count = 4\n",
    "rbf_spacing = (rbf_high - rbf_low) / rbf_count\n",
    "centers = tf.cast(tf.lin_space(rbf_low, rbf_high, rbf_count), FLOAT_TYPE)\n",
    "\n",
    "# r : [N, 3]\n",
    "r = tf.placeholder(FLOAT_TYPE, shape=(None, 3))\n",
    "\n",
    "# one_hot : [N, num_atom_types]\n",
    "one_hot = tf.placeholder(FLOAT_TYPE, shape=(None, num_atom_types))\n",
    "\n",
    "# [N, N, 3]\n",
    "rij = utils.difference_matrix(r)\n",
    "\n",
    "# [N, N, 3]\n",
    "unit_vectors = rij / tf.expand_dims(tf.norm(rij, axis=-1) + EPSILON, axis=-1)\n",
    "\n",
    "dij = utils.distance_matrix(r)\n",
    "\n",
    "# rbf : [N, N, rbf_count]\n",
    "gamma = 1. / rbf_spacing\n",
    "rbf = tf.exp(-gamma * tf.square(tf.expand_dims(dij, axis=-1) - centers))\n",
    "\n",
    "layer_dims = [15, 15, 15, 1]\n",
    "\n",
    "# EMBEDDING\n",
    "# [N, layer1_dim, 1]\n",
    "with tf.variable_scope(None, 'embed', values=[one_hot]):\n",
    "    embed = layers.self_interaction_layer_with_biases(tf.reshape(one_hot, [-1, num_atom_types, 1]), layer_dims[0])\n",
    "    input_tensor_list = {0: [embed]}\n",
    "\n",
    "# LAYERS 1-3\n",
    "num_layers = len(layer_dims) - 1\n",
    "for layer in range(num_layers):\n",
    "    layer_dim = layer_dims[layer + 1]\n",
    "    with tf.variable_scope(None, 'layer' + str(layer), values=[input_tensor_list]):\n",
    "        input_tensor_list = layers.convolution(input_tensor_list, rbf, unit_vectors)\n",
    "        input_tensor_list = layers.concatenation(input_tensor_list)\n",
    "        if layer == num_layers - 1:\n",
    "            with tf.variable_scope(None, 'atom_types', values=[input_tensor_list[0]]):\n",
    "                atom_type_list = layers.self_interaction({0: input_tensor_list[0]}, num_atom_types)\n",
    "        input_tensor_list = layers.self_interaction(input_tensor_list, layer_dim)\n",
    "        if layer < num_layers - 1:\n",
    "            with tf.variable_scope(None, 'nonlinearity', values=[input_tensor_list]):\n",
    "                input_tensor_list = layers.nonlinearity(input_tensor_list, nonlin=utils.ssp)\n",
    "\n",
    "probabilty_scalars = input_tensor_list[0][0]\n",
    "missing_coordinates = input_tensor_list[1][0]\n",
    "atom_type_scalars = atom_type_list[0][0]\n",
    "\n",
    "# [N]\n",
    "p = tf.nn.softmax(tf.squeeze(probabilty_scalars))\n",
    "\n",
    "# [N, 3] when layer3_dim == 1\n",
    "output = tf.squeeze(missing_coordinates)\n",
    "\n",
    "# votes : [N, 3]\n",
    "votes = r + output\n",
    "\n",
    "# guess_coord : [3]\n",
    "guess_coord = tf.tensordot(p, votes, [[0], [0]])\n",
    "\n",
    "# guess_atom : [num_atom_types\n",
    "guess_atom = tf.tensordot(p, tf.squeeze(atom_type_scalars), [[0], [0]])\n",
    "\n",
    "# missing_point : [3]\n",
    "missing_point = tf.placeholder(FLOAT_TYPE, shape=(3))\n",
    "missing_atom_type = tf.placeholder(FLOAT_TYPE, shape=(num_atom_types))\n",
    "\n",
    "# loss : []\n",
    "loss = tf.nn.l2_loss(missing_point - guess_coord)\n",
    "loss += tf.nn.l2_loss(missing_atom_type - guess_atom)\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 1.e-3\n",
    "step_learning_rate = 1000\n",
    "decay_factor = 0.3\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           training_set_size*step_learning_rate, decay_factor, staircase=True)\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train_op = optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "#saver.restore(sess, \"missing_point_checkpoints/qm9_model_200.ckpt\")\n",
    "\n",
    "epochs = 1000\n",
    "print_freq = 25\n",
    "save_freq = 25\n",
    "\n",
    "print(\"Training model.\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for shape, types in zip(qm9_coords, qm9_one_hot):\n",
    "        remove_index = random.randrange(len(shape))\n",
    "        new_shape = np.delete(shape, remove_index, 0)\n",
    "        new_types = np.delete(types, remove_index, 0)\n",
    "        removed_point = shape[remove_index]\n",
    "        removed_types = types[remove_index]\n",
    "        loss_to_print, _ = sess.run([loss, train_op], feed_dict={r: new_shape,\n",
    "                                      missing_point: removed_point,\n",
    "                                      missing_atom_type: removed_types,\n",
    "                                      one_hot: new_types})\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "        loss_sum = 0.\n",
    "        for shape, types in zip(qm9_coords, qm9_one_hot):\n",
    "            for remove_index in range(len(shape)):\n",
    "                new_shape = np.delete(shape, remove_index, 0)\n",
    "                new_types = np.delete(types, remove_index, 0)\n",
    "                removed_point = shape[remove_index]\n",
    "                removed_types = types[remove_index]\n",
    "                loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "                    [loss, guess_coord, guess_atom, votes, p],\n",
    "                    feed_dict={r: new_shape,\n",
    "                               missing_point: removed_point,\n",
    "                               missing_atom_type: removed_types,\n",
    "                               one_hot: new_types})\n",
    "                loss_sum += loss_value\n",
    "        print(\"train\", epoch, np.sqrt(2 * loss_sum / np.sum(list(map(len, qm9_coords)))))\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "        loss_sum = 0.\n",
    "        for shape, types in zip(qm9_test_coords, qm9_test_one_hot):\n",
    "            for remove_index in range(len(shape)):\n",
    "                new_shape = np.delete(shape, remove_index, 0)\n",
    "                new_types = np.delete(types, remove_index, 0)\n",
    "                removed_point = shape[remove_index]\n",
    "                removed_types = types[remove_index]\n",
    "                loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "                    [loss, guess_coord, guess_atom, votes, p],\n",
    "                    feed_dict={r: new_shape,\n",
    "                               missing_point: removed_point,\n",
    "                               missing_atom_type: removed_types,\n",
    "                               one_hot: new_types})\n",
    "                loss_sum += loss_value\n",
    "        print(\"test\", epoch, np.sqrt(2 * loss_sum / np.sum(list(map(len, qm9_test_coords)))))\n",
    "\n",
    "    if epoch % save_freq == 0:\n",
    "        save_path = saver.save(sess, \"missing_point_checkpoints/qm9_model_{}.ckpt\".format(epoch))\n",
    "\n",
    "        print(\"Model saved in path: %s\" % save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
